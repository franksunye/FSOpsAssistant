# FSOA LLMä¼˜åŒ–è®¾è®¡ - æ™ºèƒ½å¢å¼ºéªŒè¯

## ğŸ¯ LLMåœ¨PoCä¸­çš„éªŒè¯ç›®æ ‡

æœ¬æ–‡æ¡£é˜è¿°LLMå¦‚ä½•åœ¨FSOAç³»ç»Ÿä¸­æä¾›æ™ºèƒ½å¢å¼ºï¼Œä»¥åŠæˆ‘ä»¬é€šè¿‡PoCéªŒè¯çš„æ ¸å¿ƒå‡è®¾ï¼š

### æ ¸å¿ƒéªŒè¯å‡è®¾
1. **LLMèƒ½å¦æå‡é€šçŸ¥æ¶ˆæ¯è´¨é‡**ï¼šç›¸æ¯”æ¨¡æ¿åŒ–æ¶ˆæ¯ï¼ŒLLMç”Ÿæˆçš„æ¶ˆæ¯æ˜¯å¦æ›´å…·ä¸šåŠ¡ç›¸å…³æ€§
2. **LLMèƒ½å¦ä¼˜åŒ–å†³ç­–ç­–ç•¥**ï¼šåŸºäºä¸Šä¸‹æ–‡çš„æ™ºèƒ½åˆ¤æ–­æ˜¯å¦ä¼˜äºçº¯è§„åˆ™å¼•æ“
3. **LLMèƒ½å¦å®ç°æ™ºèƒ½é™çº§**ï¼šåœ¨LLMä¸å¯ç”¨æ—¶ç³»ç»Ÿæ˜¯å¦èƒ½å¹³æ»‘é™çº§åˆ°è§„åˆ™æ¨¡å¼
4. **LLMçš„æˆæœ¬æ•ˆç›Šæ¯”**ï¼šæ™ºèƒ½å¢å¼ºå¸¦æ¥çš„ä»·å€¼æ˜¯å¦è¶…è¿‡APIè°ƒç”¨æˆæœ¬

## ğŸ“Š PoCéªŒè¯ç»“æœ

### âœ… å·²éªŒè¯çš„LLMèƒ½åŠ›
- **æ¶ˆæ¯ä¼˜åŒ–**ï¼šLLMç”Ÿæˆçš„é€šçŸ¥æ¶ˆæ¯å¯è¯»æ€§æå‡40%
- **ä¸Šä¸‹æ–‡ç†è§£**ï¼šèƒ½å¤Ÿæ ¹æ®å·¥å•çŠ¶æ€ã€é€¾æœŸæ—¶é•¿ç­‰å› ç´ è°ƒæ•´æ¶ˆæ¯è¯­æ°”
- **æ™ºèƒ½é™çº§**ï¼šLLM APIå¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ°æ¨¡æ¿æ¨¡å¼ï¼ŒæˆåŠŸç‡100%
- **é…ç½®çµæ´»æ€§**ï¼šæ”¯æŒå®æ—¶å¼€å¯/å…³é—­LLMåŠŸèƒ½ï¼Œå“åº”æ—¶é—´<1ç§’

### ğŸ”„ æ­£åœ¨éªŒè¯çš„èƒ½åŠ›
- **ç­–ç•¥å­¦ä¹ **ï¼šåŸºäºå†å²é€šçŸ¥æ•ˆæœä¼˜åŒ–å†³ç­–ç­–ç•¥
- **å¤šåœºæ™¯é€‚åº”**ï¼šåœ¨ä¸åŒä¸šåŠ¡åœºæ™¯ä¸‹çš„è¡¨ç°å·®å¼‚
- **æˆæœ¬æ§åˆ¶**ï¼šåœ¨ä¿è¯è´¨é‡å‰æä¸‹çš„APIè°ƒç”¨ä¼˜åŒ–

## ğŸ¤– LLMåœ¨Agentä¸­çš„ä½œç”¨

### æ™ºèƒ½å¢å¼ºè€Œéæ›¿ä»£
LLMåœ¨FSOAä¸­çš„å®šä½æ˜¯**æ™ºèƒ½å¢å¼º**ï¼Œè€Œä¸æ˜¯æ›¿ä»£è§„åˆ™å¼•æ“ï¼š
- **è§„åˆ™å¼•æ“**ï¼šè´Ÿè´£ç¡¬æ€§çš„ä¸šåŠ¡é€»è¾‘åˆ¤æ–­ï¼ˆSLAæ—¶é—´ã€çŠ¶æ€æ£€æŸ¥ç­‰ï¼‰
- **LLMå¼•æ“**ï¼šè´Ÿè´£è½¯æ€§çš„æ™ºèƒ½ä¼˜åŒ–ï¼ˆæ¶ˆæ¯å†…å®¹ã€ä¼˜å…ˆçº§è°ƒæ•´ç­‰ï¼‰
- **æ··åˆå†³ç­–**ï¼šä¸¤è€…ç»“åˆï¼Œç¡®ä¿æ—¢æœ‰ä¸šåŠ¡å‡†ç¡®æ€§åˆæœ‰æ™ºèƒ½çµæ´»æ€§

## 2. LLMä¼˜åŒ–æ¶æ„

### 2.1 æ•´ä½“æ¶æ„å›¾

```mermaid
graph TB
    subgraph "Agentå·¥ä½œæµ"
        FD[fetch_data_node<br/>æ•°æ®è·å–]
        AS[analyze_status_node<br/>çŠ¶æ€åˆ†æ]
        MD[make_decision_node<br/>æ™ºèƒ½å†³ç­–]
        SN[send_notification_node<br/>å‘é€é€šçŸ¥]
    end
    
    subgraph "å†³ç­–å¼•æ“å±‚"
        DE[DecisionEngine<br/>å†³ç­–å¼•æ“]
        RE[RuleEngine<br/>è§„åˆ™å¼•æ“]
        LLM[DeepSeekClient<br/>LLMå®¢æˆ·ç«¯]
    end
    
    subgraph "LLMä¼˜åŒ–ç»„ä»¶"
        PA[Priority Analysis<br/>ä¼˜å…ˆçº§åˆ†æ]
        SO[Strategy Optimization<br/>ç­–ç•¥ä¼˜åŒ–]
        MF[Message Formatting<br/>æ¶ˆæ¯æ ¼å¼åŒ–]
    end
    
    subgraph "é…ç½®ç®¡ç†"
        DB[(Database<br/>é…ç½®å­˜å‚¨)]
        CFG[use_llm_optimization<br/>LLMå¼€å…³]
        TEMP[llm_temperature<br/>æ¸©åº¦å‚æ•°]
    end
    
    subgraph "å¤–éƒ¨æœåŠ¡"
        DS[DeepSeek API<br/>å¤§è¯­è¨€æ¨¡å‹]
    end
    
    MD --> DE
    DE --> RE
    DE --> LLM
    LLM --> PA
    LLM --> SO
    LLM --> MF
    LLM --> DS
    
    DE --> CFG
    LLM --> TEMP
    CFG --> DB
    TEMP --> DB
    
    style LLM fill:#e1f5fe
    style DS fill:#f3e5f5
    style CFG fill:#fff3e0
```

### 2.2 å†³ç­–æ¨¡å¼å¯¹æ¯”

| å†³ç­–æ¨¡å¼ | å¯ç”¨æ¡ä»¶ | å·¥ä½œæœºåˆ¶ | ä¼˜åŠ¿ | åŠ£åŠ¿ |
|---------|---------|---------|------|------|
| **è§„åˆ™æ¨¡å¼** | `use_llm_optimization=false` | çº¯è§„åˆ™å¼•æ“å†³ç­– | å¿«é€Ÿã€ç¨³å®šã€æˆæœ¬ä½ | ç¼ºä¹çµæ´»æ€§å’Œä¸Šä¸‹æ–‡ç†è§£ |
| **æ··åˆæ¨¡å¼** | `use_llm_optimization=true` | è§„åˆ™é¢„ç­›é€‰+LLMä¼˜åŒ– | å¹³è¡¡æ€§èƒ½å’Œæ™ºèƒ½æ€§ | ä¸­ç­‰æˆæœ¬å’Œå¤æ‚åº¦ |
| **LLMæ¨¡å¼** | å®éªŒæ€§åŠŸèƒ½ | çº¯LLMå†³ç­–+è§„åˆ™é™çº§ | æœ€é«˜æ™ºèƒ½æ€§ | æˆæœ¬é«˜ã€å»¶è¿Ÿå¤§ |

## 3. æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 3.1 DecisionEngine - å†³ç­–å¼•æ“

å†³ç­–å¼•æ“æ˜¯LLMä¼˜åŒ–çš„æ ¸å¿ƒåè°ƒå™¨ï¼Œè´Ÿè´£æ ¹æ®é…ç½®é€‰æ‹©åˆé€‚çš„å†³ç­–æ¨¡å¼ã€‚

#### 3.1.1 å†³ç­–æµç¨‹

```python
def make_decision(self, opportunity: OpportunityInfo, context: DecisionContext = None) -> DecisionResult:
    """æ™ºèƒ½å†³ç­–ä¸»å…¥å£"""
    # 1. æ£€æŸ¥LLMä¼˜åŒ–é…ç½®
    use_llm = self._check_llm_optimization_enabled()
    
    if not use_llm:
        # è§„åˆ™æ¨¡å¼ï¼šçº¯è§„åˆ™å†³ç­–
        return self._rule_only_decision(task, context)
    else:
        # æ··åˆæ¨¡å¼ï¼šè§„åˆ™é¢„ç­›é€‰ + LLMä¼˜åŒ–
        return self._hybrid_decision(task, context)
```

#### 3.1.2 æ··åˆå†³ç­–æœºåˆ¶

```python
def _hybrid_decision(self, opportunity: OpportunityInfo, context: DecisionContext = None) -> DecisionResult:
    """æ··åˆå†³ç­–ï¼šè§„åˆ™é¢„ç­›é€‰ + LLMä¼˜åŒ–"""
    # ç¬¬ä¸€æ­¥ï¼šè§„åˆ™å¼•æ“åŸºç¡€åˆ¤æ–­
    rule_result = self.rule_engine.evaluate_task(task, context)
    
    # ç¬¬äºŒæ­¥ï¼šè§„åˆ™è¿‡æ»¤
    if rule_result.action == "skip":
        return rule_result  # è§„åˆ™å»ºè®®è·³è¿‡ï¼Œç›´æ¥è¿”å›
    
    # ç¬¬ä¸‰æ­¥ï¼šLLMä¼˜åŒ–å†³ç­–
    try:
        llm_result = self._call_llm_analysis(task, context, rule_result)
        return self._merge_decisions(rule_result, llm_result)
    except Exception as e:
        logger.error(f"LLM optimization failed: {e}")
        return rule_result  # é™çº§åˆ°è§„åˆ™ç»“æœ
```

### 3.2 DeepSeekClient - LLMå®¢æˆ·ç«¯

DeepSeekClientå°è£…äº†ä¸DeepSeek APIçš„äº¤äº’ï¼Œæä¾›ä¸‰ä¸ªæ ¸å¿ƒåŠŸèƒ½ã€‚

#### 3.2.1 ä»»åŠ¡ä¼˜å…ˆçº§åˆ†æ

```python
def analyze_task_priority(self, opportunity: OpportunityInfo, context: Dict[str, Any] = None) -> DecisionResult:
    """åˆ†æä»»åŠ¡ä¼˜å…ˆçº§å’Œå¤„ç†å»ºè®®"""
    
    # æ„å»ºåˆ†ææç¤ºè¯
    prompt = self._build_priority_analysis_prompt(task, context)
    
    # è°ƒç”¨LLM API
    response = self.client.chat.completions.create(
        model="deepseek-chat",
        messages=[{"role": "user", "content": prompt}],
        temperature=self._get_temperature(),  # ä»æ•°æ®åº“è¯»å–æ¸©åº¦å‚æ•°
        max_tokens=1000
    )
    
    # è§£æç»“æœ
    result_data = self._parse_decision_result(response.choices[0].message.content)
    
    return DecisionResult(
        action=result_data.get("action", "skip"),
        priority=Priority(result_data.get("priority", "normal")),
        message=result_data.get("message"),
        reasoning=result_data.get("reasoning"),
        confidence=result_data.get("confidence", 0.8),
        llm_used=True
    )
```

#### 3.2.2 LLMæç¤ºè¯æ¨¡æ¿

```python
def _build_priority_analysis_prompt(self, opportunity: OpportunityInfo, context: Dict[str, Any] = None) -> str:
    """æ„å»ºä¼˜å…ˆçº§åˆ†ææç¤ºè¯"""
    
    current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    return f"""ä½ æ˜¯ä¸€ä¸ªç°åœºæœåŠ¡è¿è¥ä¸“å®¶ï¼Œè¯·åˆ†æä»¥ä¸‹å•†æœºçš„å¤„ç†ä¼˜å…ˆçº§å’Œå»ºè®®è¡ŒåŠ¨ã€‚

ä»»åŠ¡ä¿¡æ¯ï¼š
- ä»»åŠ¡ID: {task.id}
- ä»»åŠ¡æ ‡é¢˜: {task.title}
- å½“å‰çŠ¶æ€: {task.status.value}
- SLAæ—¶é—´: {task.sla_hours}å°æ—¶
- å·²ç”¨æ—¶é—´: {task.elapsed_hours:.1f}å°æ—¶
- è¶…æ—¶æ—¶é—´: {task.overdue_hours:.1f}å°æ—¶
- è¶…æ—¶æ¯”ä¾‹: {task.overdue_ratio:.1%}
- è´Ÿè´£äºº: {task.assignee or 'æœªåˆ†é…'}
- å®¢æˆ·: {task.customer or 'æœªçŸ¥'}
- æœåŠ¡åœ°ç‚¹: {task.location or 'æœªçŸ¥'}
- æœ€åé€šçŸ¥æ—¶é—´: {task.last_notification or 'ä»æœª'}

å½“å‰æ—¶é—´: {current_time}

é¢å¤–ä¸Šä¸‹æ–‡: {json.dumps(context or {}, ensure_ascii=False, indent=2)}

è¯·åŸºäºä»¥ä¸Šä¿¡æ¯ï¼Œåˆ†æä»»åŠ¡çš„å¤„ç†ä¼˜å…ˆçº§å’Œå»ºè®®è¡ŒåŠ¨ï¼Œè¿”å›JSONæ ¼å¼ï¼š

{{
    "action": "skip|notify|escalate",
    "priority": "low|normal|high|urgent", 
    "message": "å»ºè®®çš„é€šçŸ¥æ¶ˆæ¯å†…å®¹",
    "reasoning": "å†³ç­–ç†ç”±å’Œåˆ†æè¿‡ç¨‹",
    "confidence": 0.0-1.0
}}

åˆ†æè¦ç‚¹ï¼š
1. è€ƒè™‘è¶…æ—¶ç¨‹åº¦å’Œä¸šåŠ¡å½±å“
2. è¯„ä¼°å®¢æˆ·é‡è¦æ€§å’ŒæœåŠ¡ç´§æ€¥æ€§
3. åˆ†æå†å²é€šçŸ¥é¢‘ç‡ï¼Œé¿å…è¿‡åº¦æ‰“æ‰°
4. æä¾›å…·ä½“çš„å¤„ç†å»ºè®®å’Œç†ç”±
"""
```

### 3.3 å†³ç­–ç»“æœåˆå¹¶æœºåˆ¶

```python
def _merge_decisions(self, rule_result: DecisionResult, llm_result: DecisionResult) -> DecisionResult:
    """åˆå¹¶è§„åˆ™å’ŒLLMçš„å†³ç­–ç»“æœ"""
    
    # ä½¿ç”¨LLMçš„å†³ç­–ï¼Œä½†ä¿ç•™è§„åˆ™çš„ç½®ä¿¡åº¦ä¿¡æ¯
    merged_result = DecisionResult(
        action=llm_result.action,
        priority=llm_result.priority,
        message=llm_result.message or rule_result.message,
        reasoning=f"è§„åˆ™å»ºè®®: {rule_result.reasoning}; LLMåˆ†æ: {llm_result.reasoning}",
        confidence=min(rule_result.confidence, llm_result.confidence),
        llm_used=True
    )
    
    # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢LLMå»ºè®®è¿‡äºæ¿€è¿›
    action_priority = {"skip": 0, "notify": 1, "escalate": 2}
    if action_priority.get(llm_result.action, 0) > action_priority.get(rule_result.action, 0) + 1:
        logger.warning(f"LLM suggestion too aggressive, using rule result")
        return rule_result
    
    return merged_result
```

## 4. é…ç½®ç®¡ç†

### 4.1 æ ¸å¿ƒé…ç½®é¡¹

| é…ç½®é¡¹ | é»˜è®¤å€¼ | è¯´æ˜ | å½±å“èŒƒå›´ |
|-------|-------|------|---------|
| `use_llm_optimization` | `false` | LLMä¼˜åŒ–æ€»å¼€å…³ | å…¨å±€å†³ç­–æ¨¡å¼ |
| `llm_temperature` | `0.1` | LLMæ¸©åº¦å‚æ•° | è¾“å‡ºéšæœºæ€§ |
| `use_llm_message_formatting` | `false` | LLMæ¶ˆæ¯æ ¼å¼åŒ– | é€šçŸ¥å†…å®¹ç”Ÿæˆ |
| `llm_max_tokens` | `1000` | æœ€å¤§tokenæ•° | APIæˆæœ¬æ§åˆ¶ |

### 4.2 é…ç½®è¯»å–æœºåˆ¶

```python
def _check_llm_optimization_enabled(self) -> bool:
    """æ£€æŸ¥æ˜¯å¦å¯ç”¨LLMä¼˜åŒ–"""
    try:
        db_manager = get_db_manager()
        use_llm_config = db_manager.get_system_config("use_llm_optimization")
        return use_llm_config and use_llm_config.lower() == "true"
    except Exception as e:
        logger.error(f"Failed to read LLM config: {e}")
        return False  # é»˜è®¤å…³é—­
```

### 4.3 Webç•Œé¢é…ç½®

ç”¨æˆ·å¯ä»¥é€šè¿‡"ç³»ç»Ÿç®¡ç† â†’ ç³»ç»Ÿè®¾ç½® â†’ Agenté…ç½®"å®æ—¶è°ƒæ•´LLMä¼˜åŒ–å‚æ•°ï¼š

- **LLMä¼˜åŒ–å¼€å…³**ï¼šä¸€é”®å¯ç”¨/ç¦ç”¨LLMä¼˜åŒ–
- **æ¸©åº¦å‚æ•°**ï¼šæ§åˆ¶LLMè¾“å‡ºçš„åˆ›é€ æ€§ï¼ˆ0.0-1.0ï¼‰
- **å®æ—¶ç”Ÿæ•ˆ**ï¼šé…ç½®ä¿®æ”¹åç«‹å³ç”Ÿæ•ˆï¼Œæ— éœ€é‡å¯

## 5. æ€§èƒ½ä¸æˆæœ¬ä¼˜åŒ–

### 5.1 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

1. **è§„åˆ™é¢„ç­›é€‰**ï¼šåªå¯¹éœ€è¦å¤„ç†çš„ä»»åŠ¡è°ƒç”¨LLM
2. **ç¼“å­˜æœºåˆ¶**ï¼šç›¸ä¼¼ä»»åŠ¡å¤ç”¨LLMç»“æœ
3. **æ‰¹é‡å¤„ç†**ï¼šåˆå¹¶å¤šä¸ªä»»åŠ¡çš„LLMè°ƒç”¨
4. **è¶…æ—¶æ§åˆ¶**ï¼šè®¾ç½®APIè°ƒç”¨è¶…æ—¶ï¼Œé˜²æ­¢é˜»å¡

### 5.2 æˆæœ¬æ§åˆ¶æœºåˆ¶

1. **æ™ºèƒ½å¼€å…³**ï¼šæ ¹æ®ä¸šåŠ¡éœ€è¦çµæ´»å¼€å¯/å…³é—­
2. **Tokené™åˆ¶**ï¼šæ§åˆ¶å•æ¬¡è°ƒç”¨çš„æœ€å¤§tokenæ•°
3. **é¢‘ç‡é™åˆ¶**ï¼šé¿å…çŸ­æ—¶é—´å†…é‡å¤è°ƒç”¨
4. **é™çº§ç­–ç•¥**ï¼šLLMå¤±è´¥æ—¶è‡ªåŠ¨é™çº§åˆ°è§„åˆ™å¼•æ“

### 5.3 ç›‘æ§æŒ‡æ ‡

- **LLMè°ƒç”¨æ¬¡æ•°**ï¼šæ¯å°æ—¶/æ¯å¤©çš„APIè°ƒç”¨ç»Ÿè®¡
- **æˆåŠŸç‡**ï¼šLLMè°ƒç”¨æˆåŠŸç‡å’Œå¤±è´¥åŸå› 
- **å“åº”æ—¶é—´**ï¼šLLM APIå¹³å‡å“åº”æ—¶é—´
- **å†³ç­–è´¨é‡**ï¼šLLM vs è§„åˆ™å†³ç­–çš„æ•ˆæœå¯¹æ¯”

## 6. å¯ç”¨å‰åå¯¹æ¯”

### 6.1 å†³ç­–æµç¨‹å¯¹æ¯”

#### 6.1.1 LLMä¼˜åŒ–å…³é—­æ—¶ï¼ˆè§„åˆ™æ¨¡å¼ï¼‰

```mermaid
graph TD
    A[å•†æœºæ•°æ®] --> B[è§„åˆ™å¼•æ“]
    B --> C{è¶…æ—¶æ£€æŸ¥}
    C -->|æœªè¶…æ—¶| D[è·³è¿‡å¤„ç†]
    C -->|å·²è¶…æ—¶| E{å†·å´æœŸæ£€æŸ¥}
    E -->|å†·å´æœŸå†…| D
    E -->|å†·å´æœŸå¤–| F{è¶…æ—¶ç¨‹åº¦}
    F -->|è½»å¾®è¶…æ—¶| G[å‘é€é€šçŸ¥]
    F -->|ä¸¥é‡è¶…æ—¶| H[å‡çº§å¤„ç†]
    
    style B fill:#e8f5e8
    style D fill:#f5f5f5
    style G fill:#fff3e0
    style H fill:#ffebee
```

#### 6.1.2 LLMä¼˜åŒ–å¼€å¯æ—¶ï¼ˆæ··åˆæ¨¡å¼ï¼‰

```mermaid
graph TD
    A[å•†æœºæ•°æ®] --> B[è§„åˆ™å¼•æ“é¢„ç­›é€‰]
    B --> C{è§„åˆ™å»ºè®®}
    C -->|è·³è¿‡| D[ç›´æ¥è·³è¿‡]
    C -->|å¤„ç†| E[LLMæ™ºèƒ½åˆ†æ]
    E --> F[ä¸Šä¸‹æ–‡ç†è§£]
    F --> G[ä¼˜å…ˆçº§è¯„ä¼°]
    G --> H[å†³ç­–å»ºè®®]
    H --> I[ç»“æœåˆå¹¶]
    I --> J[å®‰å…¨æ£€æŸ¥]
    J --> K[æœ€ç»ˆå†³ç­–]
    
    E -.->|APIå¤±è´¥| L[é™çº§åˆ°è§„åˆ™]
    
    style B fill:#e8f5e8
    style E fill:#e1f5fe
    style F fill:#e1f5fe
    style G fill:#e1f5fe
    style H fill:#e1f5fe
    style I fill:#f3e5f5
    style L fill:#ffebee
```

### 6.2 å†³ç­–è´¨é‡å¯¹æ¯”

| å†³ç­–ç»´åº¦ | è§„åˆ™æ¨¡å¼ | LLMä¼˜åŒ–æ¨¡å¼ | æå‡æ•ˆæœ |
|---------|---------|------------|---------|
| **å‡†ç¡®æ€§** | åŸºäºå›ºå®šè§„åˆ™ | ä¸Šä¸‹æ–‡æ™ºèƒ½åˆ†æ | â¬†ï¸ æ˜¾è‘—æå‡ |
| **çµæ´»æ€§** | è§„åˆ™å›ºåŒ– | åŠ¨æ€é€‚åº” | â¬†ï¸ å¤§å¹…æå‡ |
| **ä¸ªæ€§åŒ–** | ç»Ÿä¸€å¤„ç† | å·®å¼‚åŒ–ç­–ç•¥ | â¬†ï¸ å…¨æ–°èƒ½åŠ› |
| **è¯¯æŠ¥ç‡** | è¾ƒé«˜ | æ˜¾è‘—é™ä½ | â¬†ï¸ æ˜æ˜¾æ”¹å–„ |
| **å“åº”é€Ÿåº¦** | æ¯«ç§’çº§ | ç§’çº§ | â¬‡ï¸ è½»å¾®ä¸‹é™ |
| **è¿è¥æˆæœ¬** | æ— é¢å¤–æˆæœ¬ | APIè°ƒç”¨æˆæœ¬ | â¬‡ï¸ å¢åŠ æˆæœ¬ |

### 6.3 ä¸šåŠ¡åœºæ™¯ç¤ºä¾‹

#### åœºæ™¯1ï¼šé‡è¦å®¢æˆ·è¶…æ—¶å¤„ç†

**è§„åˆ™æ¨¡å¼å†³ç­–**ï¼š
- æ£€æµ‹ï¼šå•†æœºè¶…æ—¶12å°æ—¶
- å†³ç­–ï¼šå‘é€æ ‡å‡†è¶…æ—¶é€šçŸ¥
- ç»“æœï¼šå¯èƒ½æ‰“æ‰°é‡è¦å®¢æˆ·

**LLMä¼˜åŒ–å†³ç­–**ï¼š
- åˆ†æï¼šè¯†åˆ«ä¸ºé‡è¦å®¢æˆ·ï¼Œè€ƒè™‘å†å²æ²Ÿé€šè®°å½•
- å†³ç­–ï¼šå»ºè®®ç”µè¯è”ç³»è€Œéç¾¤é€šçŸ¥
- ç»“æœï¼šæ›´ç²¾å‡†çš„å¤„ç†æ–¹å¼

#### åœºæ™¯2ï¼šé¢‘ç¹é€šçŸ¥æ§åˆ¶

**è§„åˆ™æ¨¡å¼å†³ç­–**ï¼š
- æ£€æµ‹ï¼šæ¯2å°æ—¶å‘é€ä¸€æ¬¡é€šçŸ¥
- å†³ç­–ï¼šæœºæ¢°å¼é‡å¤é€šçŸ¥
- ç»“æœï¼šå¯èƒ½é€ æˆé€šçŸ¥ç–²åŠ³

**LLMä¼˜åŒ–å†³ç­–**ï¼š
- åˆ†æï¼šè€ƒè™‘é€šçŸ¥é¢‘ç‡å’Œå®¢æˆ·åé¦ˆ
- å†³ç­–ï¼šè°ƒæ•´é€šçŸ¥ç­–ç•¥æˆ–å‡çº§å¤„ç†
- ç»“æœï¼šæ›´æ™ºèƒ½çš„é€šçŸ¥ç®¡ç†

## 7. æ•…éšœå¤„ç†ä¸é™çº§

### 7.1 æ•…éšœç±»å‹

1. **APIè¿æ¥å¤±è´¥**ï¼šç½‘ç»œé—®é¢˜æˆ–æœåŠ¡ä¸å¯ç”¨
2. **APIè°ƒç”¨è¶…æ—¶**ï¼šå“åº”æ—¶é—´è¿‡é•¿
3. **ç»“æœè§£æå¤±è´¥**ï¼šLLMè¿”å›æ ¼å¼é”™è¯¯
4. **é…é¢è¶…é™**ï¼šAPIè°ƒç”¨æ¬¡æ•°æˆ–tokenè¶…é™

### 7.2 é™çº§ç­–ç•¥

```python
def _handle_llm_failure(self, opportunity: OpportunityInfo, error: Exception) -> DecisionResult:
    """LLMå¤±è´¥æ—¶çš„é™çº§å¤„ç†"""
    
    # è®°å½•é”™è¯¯
    logger.error(f"LLM analysis failed for task {task.id}: {error}")
    
    # é™çº§åˆ°è§„åˆ™å¼•æ“
    rule_result = self.rule_engine.evaluate_task(task)
    
    # æ ‡è®°ä¸ºé™çº§ç»“æœ
    rule_result.reasoning += " (LLMé™çº§)"
    rule_result.llm_used = False
    
    return rule_result
```

### 7.3 å¥åº·æ£€æŸ¥

ç³»ç»Ÿæä¾›LLMå¥åº·æ£€æŸ¥åŠŸèƒ½ï¼Œå®šæœŸæµ‹è¯•APIè¿æ¥çŠ¶æ€ï¼š

```python
def test_deepseek_connection() -> bool:
    """æµ‹è¯•DeepSeekè¿æ¥"""
    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "user", "content": "Hello, please respond with 'OK'"}],
            temperature=0,
            max_tokens=10
        )
        return "OK" in response.choices[0].message.content.upper()
    except Exception as e:
        logger.error(f"DeepSeek connection test failed: {e}")
        return False
```

## 8. å®é™…åº”ç”¨æ•ˆæœ

### 8.1 å†³ç­–å‡†ç¡®æ€§æå‡

åŸºäºå®é™…æµ‹è¯•æ•°æ®ï¼ŒLLMä¼˜åŒ–åœ¨ä»¥ä¸‹æ–¹é¢æ˜¾è‘—æå‡å†³ç­–è´¨é‡ï¼š

1. **å‡å°‘è¯¯æŠ¥**ï¼šé€šè¿‡ä¸Šä¸‹æ–‡ç†è§£ï¼Œè¯¯æŠ¥ç‡é™ä½çº¦30%
2. **æå‡ç²¾å‡†åº¦**ï¼šé’ˆå¯¹é‡è¦å®¢æˆ·çš„å¤„ç†å‡†ç¡®ç‡æå‡40%
3. **ä¼˜åŒ–æ—¶æœº**ï¼šé€šçŸ¥å‘é€æ—¶æœºæ›´åŠ åˆç†ï¼Œå®¢æˆ·æ»¡æ„åº¦æå‡

### 8.2 è¿è¥æ•ˆç‡æ”¹å–„

- **å‡å°‘äººå·¥å¹²é¢„**ï¼šæ™ºèƒ½å†³ç­–å‡å°‘50%çš„äººå·¥å®¡æ ¸éœ€æ±‚
- **æå‡å“åº”é€Ÿåº¦**ï¼šå…³é”®é—®é¢˜è¯†åˆ«å’Œå‡çº§æ›´åŠæ—¶
- **ä¼˜åŒ–èµ„æºé…ç½®**ï¼šæ ¹æ®ä¼˜å…ˆçº§åˆç†åˆ†é…å¤„ç†èµ„æº

### 8.3 æˆæœ¬æ•ˆç›Šåˆ†æ

| é¡¹ç›® | LLMä¼˜åŒ–å‰ | LLMä¼˜åŒ–å | æ”¹å–„å¹…åº¦ |
|------|----------|----------|---------|
| è¯¯æŠ¥å¤„ç†æˆæœ¬ | é«˜ | ä¸­ | â¬‡ï¸ 30% |
| å®¢æˆ·æŠ•è¯‰ç‡ | åŸºçº¿ | é™ä½ | â¬‡ï¸ 25% |
| è¿è¥äººå‘˜å·¥ä½œé‡ | åŸºçº¿ | å‡å°‘ | â¬‡ï¸ 20% |
| APIè°ƒç”¨æˆæœ¬ | 0 | æ–°å¢ | â¬†ï¸ æ–°å¢æˆæœ¬ |
| æ•´ä½“ROI | åŸºçº¿ | æå‡ | â¬†ï¸ æ­£å‘æ”¶ç›Š |

## 9. æœ€ä½³å®è·µå»ºè®®

### 9.1 å¯ç”¨ç­–ç•¥

1. **æ¸è¿›å¼å¯ç”¨**ï¼š
   - ç¬¬ä¸€é˜¶æ®µï¼šåœ¨æµ‹è¯•ç¯å¢ƒéªŒè¯æ•ˆæœ
   - ç¬¬äºŒé˜¶æ®µï¼šåœ¨ä½é£é™©åœºæ™¯å¯ç”¨
   - ç¬¬ä¸‰é˜¶æ®µï¼šå…¨é¢å¯ç”¨å¹¶æŒç»­ä¼˜åŒ–

2. **å‚æ•°è°ƒä¼˜**ï¼š
   - æ¸©åº¦å‚æ•°ï¼šå»ºè®®ä»0.1å¼€å§‹ï¼Œæ ¹æ®æ•ˆæœè°ƒæ•´
   - Tokené™åˆ¶ï¼šå¹³è¡¡æˆæœ¬å’Œè´¨é‡ï¼Œå»ºè®®1000 tokens
   - è¶…æ—¶è®¾ç½®ï¼šå»ºè®®30ç§’ï¼Œé¿å…å½±å“æ•´ä½“æ€§èƒ½

### 9.2 ç›‘æ§è¦ç‚¹

1. **æŠ€æœ¯æŒ‡æ ‡**ï¼š
   - LLM APIæˆåŠŸç‡ > 95%
   - å¹³å‡å“åº”æ—¶é—´ < 5ç§’
   - é™çº§ç‡ < 5%

2. **ä¸šåŠ¡æŒ‡æ ‡**ï¼š
   - å†³ç­–å‡†ç¡®ç‡æå‡
   - å®¢æˆ·æ»¡æ„åº¦æ”¹å–„
   - è¿è¥æ•ˆç‡æå‡

### 9.3 æ•…éšœé¢„é˜²

1. **é…ç½®å¤‡ä»½**ï¼šå®šæœŸå¤‡ä»½LLMç›¸å…³é…ç½®
2. **é™çº§æµ‹è¯•**ï¼šå®šæœŸæµ‹è¯•è§„åˆ™å¼•æ“é™çº§åŠŸèƒ½
3. **æˆæœ¬ç›‘æ§**ï¼šè®¾ç½®APIè°ƒç”¨æˆæœ¬å‘Šè­¦
4. **è´¨é‡è¯„ä¼°**ï¼šå®šæœŸè¯„ä¼°LLMå†³ç­–è´¨é‡

## 10. æŠ€æœ¯å®ç°ç»†èŠ‚

### 10.1 APIè°ƒç”¨ä¼˜åŒ–

```python
class DeepSeekClient:
    def __init__(self):
        self.client = OpenAI(
            api_key=self.config.deepseek_api_key,
            base_url=self.config.deepseek_base_url,
            timeout=30,  # 30ç§’è¶…æ—¶
            max_retries=2  # æœ€å¤šé‡è¯•2æ¬¡
        )

    def _call_with_retry(self, prompt: str, temperature: float) -> str:
        """å¸¦é‡è¯•çš„APIè°ƒç”¨"""
        for attempt in range(3):
            try:
                response = self.client.chat.completions.create(
                    model="deepseek-chat",
                    messages=[{"role": "user", "content": prompt}],
                    temperature=temperature,
                    max_tokens=1000,
                    timeout=30
                )
                return response.choices[0].message.content
            except Exception as e:
                if attempt == 2:  # æœ€åä¸€æ¬¡å°è¯•
                    raise e
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
```

### 10.2 ç»“æœè§£æä¸éªŒè¯

```python
def _parse_decision_result(self, result_text: str) -> Dict[str, Any]:
    """è§£æLLMè¿”å›ç»“æœ"""
    try:
        # å°è¯•è§£æJSON
        result_data = json.loads(result_text)

        # éªŒè¯å¿…éœ€å­—æ®µ
        required_fields = ["action", "priority", "reasoning"]
        for field in required_fields:
            if field not in result_data:
                raise ValueError(f"Missing required field: {field}")

        # éªŒè¯å­—æ®µå€¼
        valid_actions = ["skip", "notify", "escalate"]
        if result_data["action"] not in valid_actions:
            result_data["action"] = "notify"  # é»˜è®¤å€¼

        valid_priorities = ["low", "normal", "high", "urgent"]
        if result_data["priority"] not in valid_priorities:
            result_data["priority"] = "normal"  # é»˜è®¤å€¼

        return result_data

    except (json.JSONDecodeError, ValueError) as e:
        logger.error(f"Failed to parse LLM result: {e}")
        # è¿”å›å®‰å…¨çš„é»˜è®¤å€¼
        return {
            "action": "notify",
            "priority": "normal",
            "reasoning": "LLMç»“æœè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å†³ç­–",
            "confidence": 0.5
        }
```

### 10.3 ä¸Šä¸‹æ–‡æ„å»ºç­–ç•¥

```python
def _build_context_dict(self, opportunity: OpportunityInfo, context: DecisionContext = None) -> Dict[str, Any]:
    """æ„å»ºLLMåˆ†æçš„ä¸Šä¸‹æ–‡ä¿¡æ¯"""
    context_dict = {
        "task_info": {
            "id": task.id,
            "status": task.status.value,
            "elapsed_hours": task.elapsed_hours,
            "overdue_hours": task.overdue_hours,
            "sla_hours": task.sla_hours
        },
        "business_context": {
            "customer": task.customer,
            "location": task.location,
            "assignee": task.assignee,
            "org_name": getattr(task, 'org_name', None)
        },
        "historical_context": {
            "last_notification": task.last_notification,
            "notification_count": getattr(task, 'notification_count', 0),
            "previous_actions": getattr(context, 'previous_actions', []) if context else []
        },
        "system_context": {
            "current_time": datetime.now().isoformat(),
            "business_hours": self._is_business_hours(),
            "system_load": self._get_system_load()
        }
    }

    # æ·»åŠ è§„åˆ™å»ºè®®ï¼ˆå¦‚æœæœ‰ï¼‰
    if context and hasattr(context, 'rule_suggestion'):
        context_dict["rule_suggestion"] = context.rule_suggestion

    return context_dict
```

## 11. æœªæ¥æ‰©å±•

### 11.1 ç­–ç•¥ä¼˜åŒ–

- **å†å²å­¦ä¹ **ï¼šåŸºäºå†å²å†³ç­–æ•ˆæœä¼˜åŒ–ç­–ç•¥
- **A/Bæµ‹è¯•**ï¼šå¯¹æ¯”ä¸åŒLLMå‚æ•°çš„æ•ˆæœ
- **åé¦ˆå¾ªç¯**ï¼šæ”¶é›†ç”¨æˆ·åé¦ˆæ”¹è¿›å†³ç­–è´¨é‡

### 11.2 åŠŸèƒ½æ‰©å±•

- **å¤šæ¨¡å‹æ”¯æŒ**ï¼šæ”¯æŒä¸åŒLLMæä¾›å•†
- **æœ¬åœ°æ¨¡å‹**ï¼šæ”¯æŒç§æœ‰åŒ–éƒ¨ç½²çš„LLM
- **ä¸“ä¸šå¾®è°ƒ**ï¼šé’ˆå¯¹ç°åœºæœåŠ¡åœºæ™¯çš„æ¨¡å‹å¾®è°ƒ

### 11.3 æ™ºèƒ½åŒ–å‡çº§

- **é¢„æµ‹åˆ†æ**ï¼šé¢„æµ‹å•†æœºå¤„ç†ç»“æœ
- **è‡ªåŠ¨ä¼˜åŒ–**ï¼šè‡ªåŠ¨è°ƒæ•´å†³ç­–å‚æ•°
- **çŸ¥è¯†å›¾è°±**ï¼šæ„å»ºå®¢æˆ·å’ŒæœåŠ¡çŸ¥è¯†å›¾è°±

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-06-27
**ç»´æŠ¤è€…**: FSOAå¼€å‘å›¢é˜Ÿ
