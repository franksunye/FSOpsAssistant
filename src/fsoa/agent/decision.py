"""
å†³ç­–å¼•æ“æ¨¡å—

å®ç°è§„åˆ™å¼•æ“+LLMçš„æ··åˆå†³ç­–æœºåˆ¶
"""

from datetime import datetime, timedelta

# å¯¼å…¥æ—¶åŒºå·¥å…·
from ..utils.timezone_utils import now_china_naive
from typing import Dict, Any, List, Optional
from enum import Enum

from ..data.models import OpportunityInfo, DecisionResult, Priority, DecisionContext
from ..data.database import get_db_manager
from ..utils.logger import get_logger
from ..utils.config import get_config
from .llm import get_deepseek_client

logger = get_logger(__name__)


class DecisionMode(str, Enum):
    """å†³ç­–æ¨¡å¼"""
    RULE_ONLY = "rule_only"          # ä»…è§„åˆ™
    LLM_ONLY = "llm_only"            # ä»…LLM
    HYBRID = "hybrid"                # æ··åˆæ¨¡å¼
    LLM_FALLBACK = "llm_fallback"    # LLMä¼˜å…ˆï¼Œè§„åˆ™é™çº§


class RuleEngine:
    """è§„åˆ™å¼•æ“"""
    
    def __init__(self):
        self.config = get_config()
    
    def evaluate_task(self, opportunity: OpportunityInfo, context: DecisionContext = None) -> DecisionResult:
        """
        åŸºäºè§„åˆ™è¯„ä¼°å•†æœº

        Args:
            opportunity: å•†æœºä¿¡æ¯
            context: å†³ç­–ä¸Šä¸‹æ–‡

        Returns:
            å†³ç­–ç»“æœ
        """
        logger.info(f"Evaluating opportunity {opportunity.order_num} with rules")

        # è§„åˆ™1: æ£€æŸ¥æ˜¯å¦è¶…æ—¶
        if not opportunity.is_overdue:
            return DecisionResult(
                action="skip",
                priority=Priority.LOW,
                reasoning="å•†æœºæœªè¶…æ—¶ï¼Œæ— éœ€å¤„ç†",
                confidence=1.0
            )

        # è§„åˆ™2: æ£€æŸ¥é€šçŸ¥å†·å´æ—¶é—´
        if self._is_in_cooldown(opportunity):
            return DecisionResult(
                action="skip",
                priority=Priority.LOW,
                reasoning="å•†æœºåœ¨é€šçŸ¥å†·å´æœŸå†…",
                confidence=1.0
            )

        # è§„åˆ™3: åŸºäºè¶…æ—¶ç¨‹åº¦å†³ç­–
        overdue_ratio = opportunity.overdue_hours / opportunity.sla_threshold_hours if opportunity.sla_threshold_hours > 0 else 0
        
        if overdue_ratio >= 2.0:  # è¶…æ—¶100%ä»¥ä¸Š
            return DecisionResult(
                action="escalate",
                priority=Priority.URGENT,
                message=self._generate_escalation_message(opportunity),
                reasoning=f"å•†æœºä¸¥é‡è¶…æ—¶{overdue_ratio:.1%}ï¼Œéœ€è¦å‡çº§å¤„ç†",
                confidence=1.0
            )
        elif overdue_ratio >= 1.5:  # è¶…æ—¶50%ä»¥ä¸Š
            return DecisionResult(
                action="notify",
                priority=Priority.HIGH,
                message=self._generate_high_priority_message(opportunity),
                reasoning=f"å•†æœºè¶…æ—¶{overdue_ratio:.1%}ï¼Œéœ€è¦é«˜ä¼˜å…ˆçº§é€šçŸ¥",
                confidence=1.0
            )
        elif overdue_ratio >= 1.2:  # è¶…æ—¶20%ä»¥ä¸Š
            return DecisionResult(
                action="notify",
                priority=Priority.NORMAL,
                message=self._generate_normal_message(opportunity),
                reasoning=f"å•†æœºè¶…æ—¶{overdue_ratio:.1%}ï¼Œå‘é€å¸¸è§„é€šçŸ¥",
                confidence=1.0
            )
        else:  # åˆšåˆšè¶…æ—¶
            return DecisionResult(
                action="notify",
                priority=Priority.LOW,
                message=self._generate_gentle_reminder(opportunity),
                reasoning=f"å•†æœºåˆšåˆšè¶…æ—¶{overdue_ratio:.1%}ï¼Œå‘é€æ¸©å’Œæé†’",
                confidence=1.0
            )
    
    def _is_in_cooldown(self, opportunity: OpportunityInfo) -> bool:
        """æ£€æŸ¥æ˜¯å¦åœ¨å†·å´æœŸå†…"""
        # OpportunityInfoæ²¡æœ‰last_notificationå­—æ®µï¼Œè¿™ä¸ªæ£€æŸ¥åº”è¯¥åœ¨é€šçŸ¥ç®¡ç†å™¨ä¸­å¤„ç†
        # è¿™é‡Œç®€åŒ–ä¸ºæ€»æ˜¯è¿”å›Falseï¼Œè®©é€šçŸ¥ç®¡ç†å™¨å¤„ç†å†·å´é€»è¾‘
        return False
    
    def _generate_escalation_message(self, opportunity: OpportunityInfo) -> str:
        """ç”Ÿæˆå‡çº§æ¶ˆæ¯"""
        return f"""ğŸš¨ ç´§æ€¥å‡çº§é€šçŸ¥

å·¥å•å·: {opportunity.order_num}
å®¢æˆ·: {opportunity.name}
è´Ÿè´£äºº: {opportunity.supervisor_name}
æœåŠ¡åœ°å€: {opportunity.address}
è¶…æ—¶æ—¶é—´: {opportunity.overdue_hours:.1f}å°æ—¶

âš ï¸ å•†æœºå·²ä¸¥é‡è¶…æ—¶ï¼Œéœ€è¦ç«‹å³å¤„ç†ï¼
è¯·è”ç³»ç›¸å…³è´Ÿè´£äººå¹¶è¯„ä¼°æ˜¯å¦éœ€è¦é¢å¤–èµ„æºæ”¯æŒã€‚"""

    def _generate_high_priority_message(self, opportunity: OpportunityInfo) -> str:
        """ç”Ÿæˆé«˜ä¼˜å…ˆçº§æ¶ˆæ¯"""
        return f"""âš ï¸ é«˜ä¼˜å…ˆçº§æé†’

å·¥å•å·: {opportunity.order_num}
å®¢æˆ·: {opportunity.name}
è´Ÿè´£äºº: {opportunity.supervisor_name}
è¶…æ—¶æ—¶é—´: {opportunity.overdue_hours:.1f}å°æ—¶

è¯·å°½å¿«å¤„ç†æ­¤å•†æœºï¼Œé¿å…è¿›ä¸€æ­¥å»¶è¯¯ã€‚"""

    def _generate_normal_message(self, opportunity: OpportunityInfo) -> str:
        """ç”Ÿæˆå¸¸è§„æ¶ˆæ¯"""
        return f"""â° å•†æœºè¶…æ—¶æé†’

å·¥å•å·: {opportunity.order_num}
å®¢æˆ·: {opportunity.name}
è´Ÿè´£äºº: {opportunity.supervisor_name}
è¶…æ—¶æ—¶é—´: {opportunity.overdue_hours:.1f}å°æ—¶

è¯·åŠæ—¶å¤„ç†ï¼Œç¡®ä¿æœåŠ¡è´¨é‡ã€‚"""

    def _generate_gentle_reminder(self, opportunity: OpportunityInfo) -> str:
        """ç”Ÿæˆæ¸©å’Œæé†’"""
        return f"""ğŸ“‹ å•†æœºæ—¶æ•ˆæé†’

å·¥å•å·: {opportunity.order_num}
å®¢æˆ·: {opportunity.name}
è´Ÿè´£äºº: {opportunity.supervisor_name}

å•†æœºå·²è¶…è¿‡é¢„å®šæ—¶é—´ï¼Œè¯·å…³æ³¨è¿›åº¦ã€‚"""


class DecisionEngine:
    """æ··åˆå†³ç­–å¼•æ“"""
    
    def __init__(self, mode: DecisionMode = DecisionMode.HYBRID):
        self.mode = mode
        self.rule_engine = RuleEngine()
        self.config = get_config()
        
    def make_decision(self, opportunity: OpportunityInfo, context: DecisionContext = None) -> DecisionResult:
        """
        åšå‡ºå†³ç­–

        Args:
            opportunity: å•†æœºä¿¡æ¯
            context: å†³ç­–ä¸Šä¸‹æ–‡

        Returns:
            å†³ç­–ç»“æœ
        """
        logger.info(f"Making decision for opportunity {opportunity.order_num} with mode {self.mode}")

        if self.mode == DecisionMode.RULE_ONLY:
            return self._rule_only_decision(opportunity, context)
        elif self.mode == DecisionMode.LLM_ONLY:
            return self._llm_only_decision(opportunity, context)
        elif self.mode == DecisionMode.HYBRID:
            return self._hybrid_decision(opportunity, context)
        elif self.mode == DecisionMode.LLM_FALLBACK:
            return self._llm_fallback_decision(opportunity, context)
        else:
            logger.warning(f"Unknown decision mode: {self.mode}, using rule only")
            return self._rule_only_decision(opportunity, context)
    
    def _rule_only_decision(self, opportunity: OpportunityInfo, context: DecisionContext = None) -> DecisionResult:
        """ä»…ä½¿ç”¨è§„åˆ™å†³ç­–"""
        return self.rule_engine.evaluate_task(opportunity, context)

    def _llm_only_decision(self, opportunity: OpportunityInfo, context: DecisionContext = None) -> DecisionResult:
        """ä»…ä½¿ç”¨LLMå†³ç­–"""
        try:
            deepseek_client = get_deepseek_client()
            context_dict = self._build_context_dict(opportunity, context)
            return deepseek_client.analyze_task_priority(opportunity, context_dict)
        except Exception as e:
            logger.error(f"LLM decision failed: {e}")
            # é™çº§åˆ°è§„åˆ™å†³ç­–
            return self.rule_engine.evaluate_task(opportunity, context)

    def _hybrid_decision(self, opportunity: OpportunityInfo, context: DecisionContext = None) -> DecisionResult:
        """æ··åˆå†³ç­–ï¼šè§„åˆ™é¢„ç­›é€‰ + LLMä¼˜åŒ–"""
        # é¦–å…ˆä½¿ç”¨è§„åˆ™å¼•æ“è¿›è¡ŒåŸºç¡€åˆ¤æ–­
        rule_result = self.rule_engine.evaluate_task(opportunity, context)

        # å¦‚æœè§„åˆ™å»ºè®®è·³è¿‡ï¼Œç›´æ¥è¿”å›
        if rule_result.action == "skip":
            return rule_result

        # å¯¹äºéœ€è¦å¤„ç†çš„å•†æœºï¼Œä½¿ç”¨LLMä¼˜åŒ–å†³ç­–
        try:
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨LLMä¼˜åŒ– - ä»æ•°æ®åº“è¯»å–é…ç½®
            from ..data.database import get_database_manager
            db_manager = get_database_manager()
            use_llm_config = db_manager.get_system_config("use_llm_optimization")
            use_llm = use_llm_config and use_llm_config.lower() == "true" if use_llm_config else False

            if use_llm:
                deepseek_client = get_deepseek_client()
                context_dict = self._build_context_dict(task, context)
                context_dict["rule_suggestion"] = {
                    "action": rule_result.action,
                    "priority": rule_result.priority.value,
                    "reasoning": rule_result.reasoning
                }
                
                llm_result = deepseek_client.analyze_task_priority(task, context_dict)
                
                # åˆå¹¶è§„åˆ™å’ŒLLMçš„ç»“æœ
                return self._merge_decisions(rule_result, llm_result)
            else:
                return rule_result
                
        except Exception as e:
            logger.error(f"LLM optimization failed: {e}")
            return rule_result
    
    def _llm_fallback_decision(self, task: TaskInfo, context: DecisionContext = None) -> DecisionResult:
        """LLMä¼˜å…ˆï¼Œè§„åˆ™é™çº§"""
        try:
            deepseek_client = get_deepseek_client()
            context_dict = self._build_context_dict(task, context)
            return deepseek_client.analyze_task_priority(task, context_dict)
        except Exception as e:
            logger.warning(f"LLM decision failed, falling back to rules: {e}")
            return self.rule_engine.evaluate_task(task, context)
    
    def _build_context_dict(self, task: TaskInfo, context: DecisionContext = None) -> Dict[str, Any]:
        """æ„å»ºä¸Šä¸‹æ–‡å­—å…¸"""
        context_dict = {}
        
        if context:
            # æ·»åŠ å†å²é€šçŸ¥ä¿¡æ¯
            if context.history:
                context_dict["notification_history"] = [
                    {
                        "type": notif.type,
                        "sent_at": notif.sent_at.isoformat() if notif.sent_at else None,
                        "status": notif.status.value
                    }
                    for notif in context.history[-5:]  # æœ€è¿‘5æ¡
                ]
            
            # æ·»åŠ ç¾¤ç»„é…ç½®
            if context.group_config:
                context_dict["group_config"] = {
                    "name": context.group_config.name,
                    "max_notifications_per_hour": context.group_config.max_notifications_per_hour,
                    "cooldown_minutes": context.group_config.notification_cooldown_minutes
                }
            
            # æ·»åŠ ç³»ç»Ÿé…ç½®
            if context.system_config:
                context_dict["system_config"] = context.system_config
        
        # æ·»åŠ å½“å‰æ—¶é—´ä¿¡æ¯
        now = now_china_naive()
        context_dict["current_time"] = {
            "timestamp": now.isoformat(),
            "hour": now.hour,
            "weekday": now.weekday(),
            "is_business_hours": 9 <= now.hour <= 18 and now.weekday() < 5
        }
        
        return context_dict
    
    def _merge_decisions(self, rule_result: DecisionResult, llm_result: DecisionResult) -> DecisionResult:
        """åˆå¹¶è§„åˆ™å’ŒLLMçš„å†³ç­–ç»“æœ"""
        # ä½¿ç”¨LLMçš„å†³ç­–ï¼Œä½†ä¿ç•™è§„åˆ™çš„ç½®ä¿¡åº¦ä¿¡æ¯
        merged_result = DecisionResult(
            action=llm_result.action,
            priority=llm_result.priority,
            message=llm_result.message or rule_result.message,
            reasoning=f"è§„åˆ™å»ºè®®: {rule_result.reasoning}; LLMåˆ†æ: {llm_result.reasoning}",
            confidence=min(rule_result.confidence, llm_result.confidence),
            llm_used=True
        )
        
        # å®‰å…¨æ£€æŸ¥ï¼šå¦‚æœLLMå»ºè®®çš„è¡ŒåŠ¨æ¯”è§„åˆ™æ›´æ¿€è¿›ï¼Œä½¿ç”¨è§„åˆ™ç»“æœ
        action_priority = {"skip": 0, "notify": 1, "escalate": 2}
        if action_priority.get(llm_result.action, 0) > action_priority.get(rule_result.action, 0) + 1:
            logger.warning(f"LLM suggestion too aggressive, using rule result")
            return rule_result
        
        return merged_result
    
    def get_decision_statistics(self) -> Dict[str, Any]:
        """è·å–å†³ç­–ç»Ÿè®¡ä¿¡æ¯"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ å†³ç­–ç»Ÿè®¡é€»è¾‘
        return {
            "mode": self.mode.value,
            "total_decisions": 0,
            "rule_decisions": 0,
            "llm_decisions": 0,
            "hybrid_decisions": 0
        }


def create_decision_engine(mode: str = None) -> DecisionEngine:
    """
    åˆ›å»ºå†³ç­–å¼•æ“å®ä¾‹

    Args:
        mode: å†³ç­–æ¨¡å¼

    Returns:
        å†³ç­–å¼•æ“å®ä¾‹
    """
    if mode:
        decision_mode = DecisionMode(mode)
    else:
        # ä»æ•°æ®åº“è¯»å–é»˜è®¤æ¨¡å¼
        db_manager = get_db_manager()
        use_llm_config = db_manager.get_system_config("use_llm_optimization")
        use_llm = use_llm_config and use_llm_config.lower() == "true" if use_llm_config else True
        decision_mode = DecisionMode.HYBRID if use_llm else DecisionMode.RULE_ONLY

    return DecisionEngine(decision_mode)
