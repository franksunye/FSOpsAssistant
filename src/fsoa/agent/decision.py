"""
å†³ç­–å¼•æ“æ¨¡å—

å®ç°è§„åˆ™å¼•æ“+LLMçš„æ··åˆå†³ç­–æœºåˆ¶
"""

from datetime import datetime, timedelta

# å¯¼å…¥æ—¶åŒºå·¥å…·
from ..utils.timezone_utils import now_china_naive
from typing import Dict, Any, List, Optional
from enum import Enum

from ..data.models import TaskInfo, DecisionResult, Priority, DecisionContext
from ..data.database import get_db_manager
from ..utils.logger import get_logger
from ..utils.config import get_config
from .llm import get_deepseek_client

logger = get_logger(__name__)


class DecisionMode(str, Enum):
    """å†³ç­–æ¨¡å¼"""
    RULE_ONLY = "rule_only"          # ä»…è§„åˆ™
    LLM_ONLY = "llm_only"            # ä»…LLM
    HYBRID = "hybrid"                # æ··åˆæ¨¡å¼
    LLM_FALLBACK = "llm_fallback"    # LLMä¼˜å…ˆï¼Œè§„åˆ™é™çº§


class RuleEngine:
    """è§„åˆ™å¼•æ“"""
    
    def __init__(self):
        self.config = get_config()
    
    def evaluate_task(self, task: TaskInfo, context: DecisionContext = None) -> DecisionResult:
        """
        åŸºäºè§„åˆ™è¯„ä¼°ä»»åŠ¡
        
        Args:
            task: ä»»åŠ¡ä¿¡æ¯
            context: å†³ç­–ä¸Šä¸‹æ–‡
            
        Returns:
            å†³ç­–ç»“æœ
        """
        logger.info(f"Evaluating task {task.id} with rules")
        
        # è§„åˆ™1: æ£€æŸ¥æ˜¯å¦è¶…æ—¶
        if not task.is_overdue:
            return DecisionResult(
                action="skip",
                priority=Priority.LOW,
                reasoning="ä»»åŠ¡æœªè¶…æ—¶ï¼Œæ— éœ€å¤„ç†",
                confidence=1.0
            )
        
        # è§„åˆ™2: æ£€æŸ¥é€šçŸ¥å†·å´æ—¶é—´
        if self._is_in_cooldown(task):
            return DecisionResult(
                action="skip",
                priority=Priority.LOW,
                reasoning="ä»»åŠ¡åœ¨é€šçŸ¥å†·å´æœŸå†…",
                confidence=1.0
            )
        
        # è§„åˆ™3: åŸºäºè¶…æ—¶ç¨‹åº¦å†³ç­–
        overdue_ratio = task.overdue_ratio
        
        if overdue_ratio >= 2.0:  # è¶…æ—¶100%ä»¥ä¸Š
            return DecisionResult(
                action="escalate",
                priority=Priority.URGENT,
                message=self._generate_escalation_message(task),
                reasoning=f"ä»»åŠ¡ä¸¥é‡è¶…æ—¶{overdue_ratio:.1%}ï¼Œéœ€è¦å‡çº§å¤„ç†",
                confidence=1.0
            )
        elif overdue_ratio >= 1.5:  # è¶…æ—¶50%ä»¥ä¸Š
            return DecisionResult(
                action="notify",
                priority=Priority.HIGH,
                message=self._generate_high_priority_message(task),
                reasoning=f"ä»»åŠ¡è¶…æ—¶{overdue_ratio:.1%}ï¼Œéœ€è¦é«˜ä¼˜å…ˆçº§é€šçŸ¥",
                confidence=1.0
            )
        elif overdue_ratio >= 1.2:  # è¶…æ—¶20%ä»¥ä¸Š
            return DecisionResult(
                action="notify",
                priority=Priority.NORMAL,
                message=self._generate_normal_message(task),
                reasoning=f"ä»»åŠ¡è¶…æ—¶{overdue_ratio:.1%}ï¼Œå‘é€å¸¸è§„é€šçŸ¥",
                confidence=1.0
            )
        else:  # åˆšåˆšè¶…æ—¶
            return DecisionResult(
                action="notify",
                priority=Priority.LOW,
                message=self._generate_gentle_reminder(task),
                reasoning=f"ä»»åŠ¡åˆšåˆšè¶…æ—¶{overdue_ratio:.1%}ï¼Œå‘é€æ¸©å’Œæé†’",
                confidence=1.0
            )
    
    def _is_in_cooldown(self, task: TaskInfo) -> bool:
        """æ£€æŸ¥æ˜¯å¦åœ¨å†·å´æœŸå†…"""
        if not task.last_notification:
            return False
        
        cooldown_minutes = self.config.notification_cooldown
        time_since_last = now_china_naive() - task.last_notification
        cooldown_period = timedelta(minutes=cooldown_minutes)
        
        return time_since_last < cooldown_period
    
    def _generate_escalation_message(self, task: TaskInfo) -> str:
        """ç”Ÿæˆå‡çº§æ¶ˆæ¯"""
        return f"""ğŸš¨ ç´§æ€¥å‡çº§é€šçŸ¥

ä»»åŠ¡ID: {task.id}
ä»»åŠ¡æ ‡é¢˜: {task.title}
è´Ÿè´£äºº: {task.assignee or 'æœªåˆ†é…'}
å®¢æˆ·: {task.customer or 'æœªçŸ¥'}
è¶…æ—¶æ—¶é—´: {task.overdue_hours:.1f}å°æ—¶

âš ï¸ ä»»åŠ¡å·²ä¸¥é‡è¶…æ—¶ï¼Œéœ€è¦ç«‹å³å¤„ç†ï¼
è¯·è”ç³»ç›¸å…³è´Ÿè´£äººå¹¶è¯„ä¼°æ˜¯å¦éœ€è¦é¢å¤–èµ„æºæ”¯æŒã€‚"""
    
    def _generate_high_priority_message(self, task: TaskInfo) -> str:
        """ç”Ÿæˆé«˜ä¼˜å…ˆçº§æ¶ˆæ¯"""
        return f"""âš ï¸ é«˜ä¼˜å…ˆçº§æé†’

ä»»åŠ¡ID: {task.id}
ä»»åŠ¡æ ‡é¢˜: {task.title}
è´Ÿè´£äºº: {task.assignee or 'æœªåˆ†é…'}
è¶…æ—¶æ—¶é—´: {task.overdue_hours:.1f}å°æ—¶

è¯·å°½å¿«å¤„ç†æ­¤ä»»åŠ¡ï¼Œé¿å…è¿›ä¸€æ­¥å»¶è¯¯ã€‚"""
    
    def _generate_normal_message(self, task: TaskInfo) -> str:
        """ç”Ÿæˆå¸¸è§„æ¶ˆæ¯"""
        return f"""â° ä»»åŠ¡è¶…æ—¶æé†’

ä»»åŠ¡ID: {task.id}
ä»»åŠ¡æ ‡é¢˜: {task.title}
è´Ÿè´£äºº: {task.assignee or 'æœªåˆ†é…'}
è¶…æ—¶æ—¶é—´: {task.overdue_hours:.1f}å°æ—¶

è¯·åŠæ—¶å¤„ç†ï¼Œç¡®ä¿æœåŠ¡è´¨é‡ã€‚"""
    
    def _generate_gentle_reminder(self, task: TaskInfo) -> str:
        """ç”Ÿæˆæ¸©å’Œæé†’"""
        return f"""ğŸ“‹ ä»»åŠ¡æ—¶æ•ˆæé†’

ä»»åŠ¡ID: {task.id}
ä»»åŠ¡æ ‡é¢˜: {task.title}
è´Ÿè´£äºº: {task.assignee or 'æœªåˆ†é…'}

ä»»åŠ¡å·²è¶…è¿‡é¢„å®šæ—¶é—´ï¼Œè¯·å…³æ³¨è¿›åº¦ã€‚"""


class DecisionEngine:
    """æ··åˆå†³ç­–å¼•æ“"""
    
    def __init__(self, mode: DecisionMode = DecisionMode.HYBRID):
        self.mode = mode
        self.rule_engine = RuleEngine()
        self.config = get_config()
        
    def make_decision(self, task: TaskInfo, context: DecisionContext = None) -> DecisionResult:
        """
        åšå‡ºå†³ç­–
        
        Args:
            task: ä»»åŠ¡ä¿¡æ¯
            context: å†³ç­–ä¸Šä¸‹æ–‡
            
        Returns:
            å†³ç­–ç»“æœ
        """
        logger.info(f"Making decision for task {task.id} with mode {self.mode}")
        
        if self.mode == DecisionMode.RULE_ONLY:
            return self._rule_only_decision(task, context)
        elif self.mode == DecisionMode.LLM_ONLY:
            return self._llm_only_decision(task, context)
        elif self.mode == DecisionMode.HYBRID:
            return self._hybrid_decision(task, context)
        elif self.mode == DecisionMode.LLM_FALLBACK:
            return self._llm_fallback_decision(task, context)
        else:
            logger.warning(f"Unknown decision mode: {self.mode}, using rule only")
            return self._rule_only_decision(task, context)
    
    def _rule_only_decision(self, task: TaskInfo, context: DecisionContext = None) -> DecisionResult:
        """ä»…ä½¿ç”¨è§„åˆ™å†³ç­–"""
        return self.rule_engine.evaluate_task(task, context)
    
    def _llm_only_decision(self, task: TaskInfo, context: DecisionContext = None) -> DecisionResult:
        """ä»…ä½¿ç”¨LLMå†³ç­–"""
        try:
            deepseek_client = get_deepseek_client()
            context_dict = self._build_context_dict(task, context)
            return deepseek_client.analyze_task_priority(task, context_dict)
        except Exception as e:
            logger.error(f"LLM decision failed: {e}")
            # é™çº§åˆ°è§„åˆ™å†³ç­–
            return self.rule_engine.evaluate_task(task, context)
    
    def _hybrid_decision(self, task: TaskInfo, context: DecisionContext = None) -> DecisionResult:
        """æ··åˆå†³ç­–ï¼šè§„åˆ™é¢„ç­›é€‰ + LLMä¼˜åŒ–"""
        # é¦–å…ˆä½¿ç”¨è§„åˆ™å¼•æ“è¿›è¡ŒåŸºç¡€åˆ¤æ–­
        rule_result = self.rule_engine.evaluate_task(task, context)
        
        # å¦‚æœè§„åˆ™å»ºè®®è·³è¿‡ï¼Œç›´æ¥è¿”å›
        if rule_result.action == "skip":
            return rule_result
        
        # å¯¹äºéœ€è¦å¤„ç†çš„ä»»åŠ¡ï¼Œä½¿ç”¨LLMä¼˜åŒ–å†³ç­–
        try:
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨LLMä¼˜åŒ–
            use_llm = getattr(self.config, 'use_llm_optimization', False)
            if use_llm:
                deepseek_client = get_deepseek_client()
                context_dict = self._build_context_dict(task, context)
                context_dict["rule_suggestion"] = {
                    "action": rule_result.action,
                    "priority": rule_result.priority.value,
                    "reasoning": rule_result.reasoning
                }
                
                llm_result = deepseek_client.analyze_task_priority(task, context_dict)
                
                # åˆå¹¶è§„åˆ™å’ŒLLMçš„ç»“æœ
                return self._merge_decisions(rule_result, llm_result)
            else:
                return rule_result
                
        except Exception as e:
            logger.error(f"LLM optimization failed: {e}")
            return rule_result
    
    def _llm_fallback_decision(self, task: TaskInfo, context: DecisionContext = None) -> DecisionResult:
        """LLMä¼˜å…ˆï¼Œè§„åˆ™é™çº§"""
        try:
            deepseek_client = get_deepseek_client()
            context_dict = self._build_context_dict(task, context)
            return deepseek_client.analyze_task_priority(task, context_dict)
        except Exception as e:
            logger.warning(f"LLM decision failed, falling back to rules: {e}")
            return self.rule_engine.evaluate_task(task, context)
    
    def _build_context_dict(self, task: TaskInfo, context: DecisionContext = None) -> Dict[str, Any]:
        """æ„å»ºä¸Šä¸‹æ–‡å­—å…¸"""
        context_dict = {}
        
        if context:
            # æ·»åŠ å†å²é€šçŸ¥ä¿¡æ¯
            if context.history:
                context_dict["notification_history"] = [
                    {
                        "type": notif.type,
                        "sent_at": notif.sent_at.isoformat() if notif.sent_at else None,
                        "status": notif.status.value
                    }
                    for notif in context.history[-5:]  # æœ€è¿‘5æ¡
                ]
            
            # æ·»åŠ ç¾¤ç»„é…ç½®
            if context.group_config:
                context_dict["group_config"] = {
                    "name": context.group_config.name,
                    "max_notifications_per_hour": context.group_config.max_notifications_per_hour,
                    "cooldown_minutes": context.group_config.notification_cooldown_minutes
                }
            
            # æ·»åŠ ç³»ç»Ÿé…ç½®
            if context.system_config:
                context_dict["system_config"] = context.system_config
        
        # æ·»åŠ å½“å‰æ—¶é—´ä¿¡æ¯
        now = now_china_naive()
        context_dict["current_time"] = {
            "timestamp": now.isoformat(),
            "hour": now.hour,
            "weekday": now.weekday(),
            "is_business_hours": 9 <= now.hour <= 18 and now.weekday() < 5
        }
        
        return context_dict
    
    def _merge_decisions(self, rule_result: DecisionResult, llm_result: DecisionResult) -> DecisionResult:
        """åˆå¹¶è§„åˆ™å’ŒLLMçš„å†³ç­–ç»“æœ"""
        # ä½¿ç”¨LLMçš„å†³ç­–ï¼Œä½†ä¿ç•™è§„åˆ™çš„ç½®ä¿¡åº¦ä¿¡æ¯
        merged_result = DecisionResult(
            action=llm_result.action,
            priority=llm_result.priority,
            message=llm_result.message or rule_result.message,
            reasoning=f"è§„åˆ™å»ºè®®: {rule_result.reasoning}; LLMåˆ†æ: {llm_result.reasoning}",
            confidence=min(rule_result.confidence, llm_result.confidence),
            llm_used=True
        )
        
        # å®‰å…¨æ£€æŸ¥ï¼šå¦‚æœLLMå»ºè®®çš„è¡ŒåŠ¨æ¯”è§„åˆ™æ›´æ¿€è¿›ï¼Œä½¿ç”¨è§„åˆ™ç»“æœ
        action_priority = {"skip": 0, "notify": 1, "escalate": 2}
        if action_priority.get(llm_result.action, 0) > action_priority.get(rule_result.action, 0) + 1:
            logger.warning(f"LLM suggestion too aggressive, using rule result")
            return rule_result
        
        return merged_result
    
    def get_decision_statistics(self) -> Dict[str, Any]:
        """è·å–å†³ç­–ç»Ÿè®¡ä¿¡æ¯"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ å†³ç­–ç»Ÿè®¡é€»è¾‘
        return {
            "mode": self.mode.value,
            "total_decisions": 0,
            "rule_decisions": 0,
            "llm_decisions": 0,
            "hybrid_decisions": 0
        }


def create_decision_engine(mode: str = None) -> DecisionEngine:
    """
    åˆ›å»ºå†³ç­–å¼•æ“å®ä¾‹
    
    Args:
        mode: å†³ç­–æ¨¡å¼
        
    Returns:
        å†³ç­–å¼•æ“å®ä¾‹
    """
    if mode:
        decision_mode = DecisionMode(mode)
    else:
        # ä»é…ç½®ä¸­è¯»å–é»˜è®¤æ¨¡å¼
        config = get_config()
        use_llm = getattr(config, 'use_llm_optimization', True)
        decision_mode = DecisionMode.HYBRID if use_llm else DecisionMode.RULE_ONLY
    
    return DecisionEngine(decision_mode)
